{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  INSTALL DEPENDENCY AND LIBRARIES\n",
    "# multiple output model\n",
    "import os # os library help us to work with the different file faucets\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# tensorflow and tensorflow-gpu  are going to be deep learning models - keras\n",
    "#  will be used to create sequential model\n",
    "#  -pandas will help in reading the tabular data \n",
    "#  matplotlib - helps for some plotting\n",
    "#  sklearn\n",
    "# numpy - numpy is used as np.expand_dims  --> wrap up any of the information inside\n",
    "# the another set of array ---> used when we got one sample in our batch\n",
    "# and we want to pass it through our deep learning models bcz we are expecting multiple examples\n",
    "# in that particular batch so we normally wrap it up inside of that \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a0916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing our data \n",
    "df = pd.read_csv( # here we use pd.read_csv function to read the csv\n",
    "    os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv')\n",
    "#     os.path.join ---> gives us the full path to our dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1465834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22540be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81151d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[6]['comment_text']\n",
    "#  example of toxic comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781485d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            1\n",
       "severe_toxic     1\n",
       "obscene          1\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "Name: 6, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3411a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preprocessing to get the data ready for modelling \n",
    "# -- Tokenization --->  translating sentence into tokens which only deep nueral network understands\n",
    "#  -- unique identifier so each word maps out to a number \n",
    "# we will also create training testing and validation partition as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cbee0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "# textvectorization is used for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4f3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values\n",
    "# .values convert it into numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469dd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e57883",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')\n",
    "# output_sequence_length ---> maximum length of the sentence in our token \n",
    "# output_mode in the form of integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573bad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)\n",
    "# adapt will help us to learn all the words in vocabulary \n",
    "# we use  X.values cuz we need numpy array instead of pandas series\n",
    "# vectorizer.get_vocabulary()  ---> can also be used to get the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df33e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer(\"Hello world, life is great\")[:5]\n",
    "#  removes the punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22d5ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)\n",
    "#  here we will pass all our x values through the vectorizer and we gonna get the vectorized_text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f610de2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  643,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2506, ...,     0,     0,     0],\n",
       "       [  425,   440,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32141,  7329,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   533, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text\n",
    "# numeric representation of all of our sentences \n",
    "#  if our sentence doesn't need max length then it fills the rest with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd9a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC SHBAP -- map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))  # we create our dataset\n",
    "dataset = dataset.cache() # caches the data\n",
    "dataset = dataset.shuffle(160000) # shuffles \n",
    "dataset = dataset.batch(16) #batches it up in series of 16 samples \n",
    "dataset = dataset.prefetch(8) # helps bottlenecks\n",
    "\n",
    "#  we gonna create a tensorflow data pipeline \n",
    "# dataset.as_numpy_iterator().next()  ---> gets us the batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e78d4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X,batch_Y=dataset.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd43339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2)) # we are skipping 70 percent and grabbing 20 percent \n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1)) # we arre skipping 30 percent and grabbing 10 percent\n",
    "# training , validation ,test partition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5cc800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e48835c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1417,   45,   35, ...,    0,    0,    0],\n",
       "        [ 102, 1562,   72, ...,    0,    0,    0],\n",
       "        [  86,  848,  178, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   7,   69,   54, ...,    0,    0,    0],\n",
       "        [4581,  350, 1049, ...,    0,    0,    0],\n",
       "        [  32,    2,  108, ...,    0,    0,    0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next() #here we could see all the iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30f7fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an deep learning model\n",
    "#   ----> How do we actually take this words and give them to a deep learning model?\n",
    "#     first layer -- embedding layer -->  embedding that maps to a word knows a lot about that word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "264b8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequential model - gonna use sequential api \n",
    "# we could build this model through other ways also sequential model is the fastest and easiest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "352ec67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding # bringing in a bunch of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c015705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the layers which we are going to use to build a deep nueral network\n",
    "# lstm layers are going to be our starting layers , bidirectioal layer is going to be our modifier on top of that and it's going to allow us to pass the features or values from our lstm outputs across the board as we're passing through our sequences\n",
    "# Dropout is a method of regularisation & our dense layer is our fully connected layer and so we are going to again bring in sequential and bunch of layers down here\n",
    "# we are going to pass through our sequences to our embedding that converts like the personality test per word and that is learned as we pass through our deep nueral network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d600f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # instantiate our model\n",
    "# Create the embedding layer \n",
    "model.add(Embedding(MAX_FEATURES+1,32)) # max- feature = number of words and +1 is done for unkown words which gonna have their own separate embedding\n",
    "#  how many different types of embedding we gonna need \n",
    "# MAX_FEATURES+1 == how many words we gonna have & 32 == how many features we gonna have in our embedding \n",
    "#  one embedding per word --> our embedding is gonna be 32 values in length\n",
    "# 200,001 different types of embedding  and there gonna be 32 values long\n",
    " \n",
    "    \n",
    "\n",
    "# Creating our lstm layer \n",
    "model.add(Bidirectional(LSTM(32,activation = 'tanh')))\n",
    "# lstm layer is gonna have 32 different lstm units and specify the activation of tanh\n",
    "# reason we are using tanh over relu bcz the gpu acceleration that is required for lstm layer needs to be tanh\n",
    "# bi-directioanl allows you to pass the information backwards and forwards across the lstm layer \n",
    "# sequence ouputting information in one direction  but bi directional allow in two directions\n",
    "# two direction in sentences is useful bcz words prior to current word will still have meaning might even modify a meaning \n",
    "# ex - i don't hate you --> if it one direction then hate will make it negative but with bi direction don't will also be remembered which will give it it's actual meaning \n",
    "# using biderecctional layer when it comes to nlp helps a lot\n",
    "# attention or self attention helps with transformers and transform and make it easier to work with \n",
    "\n",
    "\n",
    "# Dense layers  --> three feature extractors \n",
    "# FEature extractor fully connected layers \n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "#Final layer\n",
    "# maps to the number of different outputs that we have got inside of our neural network \n",
    "# y values we have 159571 samples with  6 different values or vectors\n",
    "# by having 6 final units in our dense layer  we are gonna be output the exact same style of output as our labels\n",
    "# sigmoid activation - it's gonna transform any given output that we gonna get from features layer into a value between 0 and 1 \n",
    "# activation acts like a modifier and it allows us to  take non linerities into account when building a deep neural network\n",
    "model.add(Dense(6,activation='sigmoid'))\n",
    "# deep neural network created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d9b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer = 'Adam')\n",
    "#compile the model\n",
    "#   there are six lines coming out shouldn't this be categorical cross entropy ?\n",
    "#    it's like we are running almost six binary classifier almost at same time \n",
    "#   we are having multi output model -->\n",
    "# other optimizer like sjd can also be used \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66e96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd4b61d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "6981/6981 [==============================] - 7097s 1s/step - loss: 0.0610 - val_loss: 0.0440\n",
      "Epoch 2/7\n",
      "6981/6981 [==============================] - 6523s 934ms/step - loss: 0.0451 - val_loss: 0.0396\n",
      "Epoch 3/7\n",
      "6981/6981 [==============================] - 6813s 976ms/step - loss: 0.0407 - val_loss: 0.0368\n",
      "Epoch 4/7\n",
      "6981/6981 [==============================] - 6403s 917ms/step - loss: 0.0357 - val_loss: 0.0329\n",
      "Epoch 5/7\n",
      "6981/6981 [==============================] - 5938s 851ms/step - loss: 0.0318 - val_loss: 0.0279\n",
      "Epoch 6/7\n",
      "6981/6981 [==============================] - 5818s 833ms/step - loss: 0.0290 - val_loss: 0.0258\n",
      "Epoch 7/7\n",
      "6981/6981 [==============================] - 6350s 910ms/step - loss: 0.0260 - val_loss: 0.0214\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,epochs=7,validation_data=val)\n",
    "    # training the model \n",
    "    #epochs is how long you want to train the model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa4b538c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.060975585132837296,\n",
       "  0.04514980688691139,\n",
       "  0.040744226425886154,\n",
       "  0.035673242062330246,\n",
       "  0.03180287405848503,\n",
       "  0.029014231637120247,\n",
       "  0.025992179289460182],\n",
       " 'val_loss': [0.04399886354804039,\n",
       "  0.03957647830247879,\n",
       "  0.03680085390806198,\n",
       "  0.032866720110177994,\n",
       "  0.02786983922123909,\n",
       "  0.025823917239904404,\n",
       "  0.021403536200523376]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1751e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46a0beb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a100ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "input_text = vectorizer('You freaking suck!, I  punch you')\n",
    "# vectorized the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc3eaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570c552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X,batch_Y=test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ed9af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(input_text)\n",
    "#  it will fail cuz the  we have not passed it as a batch or series of values and its only single value\n",
    "#  number of values in sequence * number of embedding  which will be input shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0834971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array([input_text]))\n",
    "#  by converting the input text into numpy array we could get it as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93d1747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.expand_dims(input_text,0)\n",
    "#  it will do the same thing as np.array but it is little bit cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49787eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35eda6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X)>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "789ef62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37ff4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluation -- > Precision Recall Categorical Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bef94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ca117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre= Precision()\n",
    "re= Recall()\n",
    "acc= CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acaba3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():   # iterate through every single batch in our data pipeline\n",
    "    #Unpack the batch\n",
    "    X_true, y_true = batch\n",
    "    #Make a prediction\n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    #Flatten the predictions - making them in one single big array instead of 2d\n",
    "    y_true = y_true.flatten()\n",
    "    yhat=yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true,yhat)\n",
    "    re.update_state(y_true,yhat)\n",
    "    acc.update_state(y_true,yhat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63c6ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8936361074447632, Recall:0.8901785612106323, Accuracy:0.5366098284721375\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb64fac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.3-py3-none-any.whl (6.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.2-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp39-cp39-win_amd64.whl (554 kB)\n",
      "Collecting websockets\n",
      "  Downloading websockets-10.3-cp39-cp39-win_amd64.whl (98 kB)\n",
      "Collecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "Collecting h11<0.13,>=0.11\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.82.0-py3-none-any.whl (55 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-win_amd64.whl (1.9 MB)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (1.20.3)\n",
      "Collecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (1.3.4)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (2021.10.1)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.0-cp39-none-win_amd64.whl (197 kB)\n",
      "Requirement already satisfied: paramiko in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (2.7.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (8.4.0)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from gradio) (2.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from jinja2) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (21.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (3.2)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from analytics-python->gradio) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from analytics-python->gradio) (1.16.0)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from requests->gradio) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from requests->gradio) (1.26.7)\n",
      "Collecting starlette==0.19.1\n",
      "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from starlette==0.19.1->fastapi->gradio) (3.10.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Collecting typing-extensions>=3.10.0\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.16.0,>=0.15.0\n",
      "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "Collecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from pandas->gradio) (2021.3)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from paramiko->gradio) (3.2.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from paramiko->gradio) (1.4.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from paramiko->gradio) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.1 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\saransh\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.4)\n",
      "Building wheels for collected packages: ffmpy, python-multipart\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=0225216b86847fcfc8135bbbacf73f052f4d7e5065ed10533a243fa920ac1edc\n",
      "  Stored in directory: c:\\users\\saransh\\appdata\\local\\pip\\cache\\wheels\\91\\e2\\96\\f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "  Building wheel for python-multipart (setup.py): started\n",
      "  Building wheel for python-multipart (setup.py): finished with status 'done'\n",
      "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=ad3d2abe49caf4aa8f3964509370384cd398f49c701789e093b517ac482135d6\n",
      "  Stored in directory: c:\\users\\saransh\\appdata\\local\\pip\\cache\\wheels\\fe\\04\\d1\\a10661cc45f03c3cecda50deb2d2c22f57b4e84a75b2a5987e\n",
      "Successfully built ffmpy python-multipart\n",
      "Installing collected packages: mdurl, uc-micro-py, typing-extensions, rfc3986, multidict, markdown-it-py, h11, frozenlist, anyio, yarl, starlette, pydantic, monotonic, mdit-py-plugins, linkify-it-py, httpcore, backoff, async-timeout, aiosignal, websockets, uvicorn, python-multipart, pydub, pycryptodome, orjson, httpx, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 2.2.0\n",
      "    Uninstalling anyio-2.2.0:\n",
      "      Successfully uninstalled anyio-2.2.0\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.6.1 async-timeout-4.0.2 backoff-1.10.0 fastapi-0.82.0 ffmpy-0.3.0 frozenlist-1.3.1 gradio-3.3 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.2 monotonic-1.6 multidict-6.0.2 orjson-3.8.0 pycryptodome-3.15.0 pydantic-1.10.2 pydub-0.25.1 python-multipart-0.0.5 rfc3986-1.5.0 starlette-0.19.1 typing-extensions-4.3.0 uc-micro-py-1.0.1 uvicorn-0.18.3 websockets-10.3 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08999838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name dataclass_transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10908/4127191075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gradio\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpkgutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gradio\\components.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmedia_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocumentation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_documentation_group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m from gradio.events import (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0manyio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCapacityLimiter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m from gradio import (\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mcomponents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mencryptor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gradio\\event_queue.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fastapi\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstarlette\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackground\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBackgroundTasks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBackgroundTasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdatastructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUploadFile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUploadFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrouting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDefaultPlaceholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictIntStrAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSetIntStr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDefaultPlaceholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDependant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\fastapi\\params.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUndefined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\__init__.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36minit pydantic.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\dataclasses.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36minit pydantic.dataclasses\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name dataclass_transform"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4294f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82109098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
